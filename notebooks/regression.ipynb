{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes_df = pd.read_csv('dataset/pipes_df.csv')\n",
    "spills_df = pd.read_csv('dataset/spills_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lon_start</th>\n",
       "      <th>lat_start</th>\n",
       "      <th>lon_end</th>\n",
       "      <th>lat_end</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-04 06:42:19+00:00</td>\n",
       "      <td>73.033226</td>\n",
       "      <td>60.588367</td>\n",
       "      <td>73.044554</td>\n",
       "      <td>60.594281</td>\n",
       "      <td>0_2021_06_04_06_42_19.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-09 06:42:19+00:00</td>\n",
       "      <td>73.033226</td>\n",
       "      <td>60.588367</td>\n",
       "      <td>73.044554</td>\n",
       "      <td>60.594281</td>\n",
       "      <td>1_2021_06_09_06_42_19.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-11 06:32:21+00:00</td>\n",
       "      <td>73.033226</td>\n",
       "      <td>60.588367</td>\n",
       "      <td>73.044554</td>\n",
       "      <td>60.594281</td>\n",
       "      <td>2_2021_06_11_06_32_21.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-14 06:42:20+00:00</td>\n",
       "      <td>73.033226</td>\n",
       "      <td>60.588367</td>\n",
       "      <td>73.044554</td>\n",
       "      <td>60.594281</td>\n",
       "      <td>3_2021_06_14_06_42_20.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-26 06:32:22+00:00</td>\n",
       "      <td>73.033226</td>\n",
       "      <td>60.588367</td>\n",
       "      <td>73.044554</td>\n",
       "      <td>60.594281</td>\n",
       "      <td>4_2021_06_26_06_32_22.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time  lon_start  lat_start    lon_end    lat_end  \\\n",
       "0  2021-06-04 06:42:19+00:00  73.033226  60.588367  73.044554  60.594281   \n",
       "1  2021-06-09 06:42:19+00:00  73.033226  60.588367  73.044554  60.594281   \n",
       "2  2021-06-11 06:32:21+00:00  73.033226  60.588367  73.044554  60.594281   \n",
       "3  2021-06-14 06:42:20+00:00  73.033226  60.588367  73.044554  60.594281   \n",
       "4  2021-06-26 06:32:22+00:00  73.033226  60.588367  73.044554  60.594281   \n",
       "\n",
       "                        name  \n",
       "0  0_2021_06_04_06_42_19.npy  \n",
       "1  1_2021_06_09_06_42_19.npy  \n",
       "2  2_2021_06_11_06_32_21.npy  \n",
       "3  3_2021_06_14_06_42_20.npy  \n",
       "4  4_2021_06_26_06_32_22.npy  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = ['band_' + str(i) for i in range(1, 20)]\n",
    "\n",
    "for col in new_cols:\n",
    "    pipes_df[f'{col}'] = 0.0\n",
    "    spills_df[f'{col}'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time          object\n",
       "lon_start    float64\n",
       "lat_start    float64\n",
       "lon_end      float64\n",
       "lat_end      float64\n",
       "name          object\n",
       "band_1       float64\n",
       "band_2       float64\n",
       "band_3       float64\n",
       "band_4       float64\n",
       "band_5       float64\n",
       "band_6       float64\n",
       "band_7       float64\n",
       "band_8       float64\n",
       "band_9       float64\n",
       "band_10      float64\n",
       "band_11      float64\n",
       "band_12      float64\n",
       "band_13      float64\n",
       "band_14      float64\n",
       "band_15      float64\n",
       "band_16      float64\n",
       "band_17      float64\n",
       "band_18      float64\n",
       "band_19      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipes_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'pipes_frames'\n",
    "for i in range(len(pipes_df)):\n",
    "    np_array = np.mean(np.load('dataset/' + folder + '/' + pipes_df.iloc[i, 5]), axis= (0, 1))\n",
    "    for j in range(19):\n",
    "        pipes_df.iloc[i, 6+j] = np_array[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'spills_frames'\n",
    "for i in range(len(spills_df)):\n",
    "    np_array = np.mean(np.load('dataset/' + folder + '/' + spills_df.iloc[i, 5]), axis= (0, 1))\n",
    "    for j in range(19):\n",
    "        spills_df.iloc[i, 6+j] = np_array[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23320"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pipes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55429"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spills_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes_df['y'] = 0\n",
    "spills_df['y'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46640"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([pipes_df, spills_df[:23320]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time         0\n",
       "lon_start    0\n",
       "lat_start    0\n",
       "lon_end      0\n",
       "lat_end      0\n",
       "name         0\n",
       "band_1       0\n",
       "band_2       0\n",
       "band_3       0\n",
       "band_4       0\n",
       "band_5       0\n",
       "band_6       0\n",
       "band_7       0\n",
       "band_8       0\n",
       "band_9       0\n",
       "band_10      0\n",
       "band_11      0\n",
       "band_12      0\n",
       "band_13      0\n",
       "band_14      0\n",
       "band_15      0\n",
       "band_16      0\n",
       "band_17      0\n",
       "band_18      0\n",
       "band_19      0\n",
       "y            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lon_start</th>\n",
       "      <th>lat_start</th>\n",
       "      <th>lon_end</th>\n",
       "      <th>lat_end</th>\n",
       "      <th>name</th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>band_3</th>\n",
       "      <th>band_4</th>\n",
       "      <th>...</th>\n",
       "      <th>band_11</th>\n",
       "      <th>band_12</th>\n",
       "      <th>band_13</th>\n",
       "      <th>band_14</th>\n",
       "      <th>band_15</th>\n",
       "      <th>band_16</th>\n",
       "      <th>band_17</th>\n",
       "      <th>band_18</th>\n",
       "      <th>band_19</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>2017-11-14 06:31:20+00:00</td>\n",
       "      <td>76.828511</td>\n",
       "      <td>62.973044</td>\n",
       "      <td>76.841490</td>\n",
       "      <td>62.978622</td>\n",
       "      <td>338_2017_11_14_06_31_20.npy</td>\n",
       "      <td>5.554585</td>\n",
       "      <td>4.957737</td>\n",
       "      <td>4.387348</td>\n",
       "      <td>4.383430</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000899</td>\n",
       "      <td>1.075346</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.818604</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>98.966797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>2017-01-28 06:31:18+00:00</td>\n",
       "      <td>77.796593</td>\n",
       "      <td>61.160410</td>\n",
       "      <td>77.808982</td>\n",
       "      <td>61.165903</td>\n",
       "      <td>1964_2017_01_28_06_31_18.npy</td>\n",
       "      <td>5.948438</td>\n",
       "      <td>5.389093</td>\n",
       "      <td>4.700345</td>\n",
       "      <td>4.884093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901235</td>\n",
       "      <td>0.948141</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.173828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.618652</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.945801</td>\n",
       "      <td>70.621094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17516</th>\n",
       "      <td>2021-09-14 07:22:07+00:00</td>\n",
       "      <td>65.167159</td>\n",
       "      <td>61.238427</td>\n",
       "      <td>65.179470</td>\n",
       "      <td>61.243978</td>\n",
       "      <td>17516_2021_09_14_07_22_07.npy</td>\n",
       "      <td>0.044310</td>\n",
       "      <td>0.182841</td>\n",
       "      <td>0.474609</td>\n",
       "      <td>0.343843</td>\n",
       "      <td>...</td>\n",
       "      <td>1.258765</td>\n",
       "      <td>0.638736</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.293945</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.047852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8437</th>\n",
       "      <td>2021-08-08 06:42:21+00:00</td>\n",
       "      <td>72.322506</td>\n",
       "      <td>60.585428</td>\n",
       "      <td>72.333701</td>\n",
       "      <td>60.591401</td>\n",
       "      <td>8437_2021_08_08_06_42_21.npy</td>\n",
       "      <td>0.983284</td>\n",
       "      <td>0.971399</td>\n",
       "      <td>1.094694</td>\n",
       "      <td>0.838801</td>\n",
       "      <td>...</td>\n",
       "      <td>1.553472</td>\n",
       "      <td>0.817796</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>5.156006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>140.091309</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.002441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>2021-06-13 07:12:48+00:00</td>\n",
       "      <td>64.681758</td>\n",
       "      <td>59.914256</td>\n",
       "      <td>64.693491</td>\n",
       "      <td>59.919854</td>\n",
       "      <td>3200_2021_06_13_07_12_48.npy</td>\n",
       "      <td>0.481450</td>\n",
       "      <td>0.565567</td>\n",
       "      <td>0.708040</td>\n",
       "      <td>0.572855</td>\n",
       "      <td>...</td>\n",
       "      <td>1.457682</td>\n",
       "      <td>0.867603</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.100830</td>\n",
       "      <td>0.937744</td>\n",
       "      <td>106.519531</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            time  lon_start  lat_start    lon_end    lat_end  \\\n",
       "338    2017-11-14 06:31:20+00:00  76.828511  62.973044  76.841490  62.978622   \n",
       "1964   2017-01-28 06:31:18+00:00  77.796593  61.160410  77.808982  61.165903   \n",
       "17516  2021-09-14 07:22:07+00:00  65.167159  61.238427  65.179470  61.243978   \n",
       "8437   2021-08-08 06:42:21+00:00  72.322506  60.585428  72.333701  60.591401   \n",
       "3200   2021-06-13 07:12:48+00:00  64.681758  59.914256  64.693491  59.919854   \n",
       "\n",
       "                                name    band_1    band_2    band_3    band_4  \\\n",
       "338      338_2017_11_14_06_31_20.npy  5.554585  4.957737  4.387348  4.383430   \n",
       "1964    1964_2017_01_28_06_31_18.npy  5.948438  5.389093  4.700345  4.884093   \n",
       "17516  17516_2021_09_14_07_22_07.npy  0.044310  0.182841  0.474609  0.343843   \n",
       "8437    8437_2021_08_08_06_42_21.npy  0.983284  0.971399  1.094694  0.838801   \n",
       "3200    3200_2021_06_13_07_12_48.npy  0.481450  0.565567  0.708040  0.572855   \n",
       "\n",
       "       ...   band_11   band_12  band_13   band_14   band_15     band_16  \\\n",
       "338    ...  1.000899  1.075346   0.0002  0.000000  0.000000   31.818604   \n",
       "1964   ...  0.901235  0.948141   0.0002  0.173828  0.000000   23.618652   \n",
       "17516  ...  1.258765  0.638736   0.0001  0.000977  0.000000   17.293945   \n",
       "8437   ...  1.553472  0.817796   0.0004  5.156006  1.000000  140.091309   \n",
       "3200   ...  1.457682  0.867603   0.0001  0.100830  0.937744  106.519531   \n",
       "\n",
       "       band_17    band_18    band_19  y  \n",
       "338        1.0  11.000000  98.966797  1  \n",
       "1964       1.0  10.945801  70.621094  1  \n",
       "17516      1.0   4.047852   0.000000  0  \n",
       "8437       1.0   5.002441   0.000000  0  \n",
       "3200       1.0  10.000000   0.000000  0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['time', 'lon_start', 'lat_start', 'lon_end', 'lat_end', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['ndvi'] = (train_df['band_8'] - train_df['band_4'])/(train_df['band_8'] + train_df['band_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_list = train_df.select_dtypes(include=[np.number]).columns\n",
    "train_df[numeric_list] = train_df[numeric_list].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "band_1     float32\n",
       "band_2     float32\n",
       "band_3     float32\n",
       "band_4     float32\n",
       "band_5     float32\n",
       "band_6     float32\n",
       "band_7     float32\n",
       "band_8     float32\n",
       "band_9     float32\n",
       "band_10    float32\n",
       "band_11    float32\n",
       "band_12    float32\n",
       "band_13    float32\n",
       "band_14    float32\n",
       "band_15    float32\n",
       "band_16    float32\n",
       "band_17    float32\n",
       "band_18    float32\n",
       "band_19    float32\n",
       "y          float32\n",
       "ndvi       float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_df.sample(frac=0.9, random_state=0)\n",
    "test_dataset = train_df.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('y')\n",
    "test_labels = test_features.pop('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.experimental.preprocessing.Normalization(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer.adapt(np.array(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.preprocessing.normalization.Normalization at 0x1b528936d60>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First example: [[ 0.83  0.83  1.09  1.17  1.65  2.31  2.52  2.73  2.78  2.92  2.37  1.87\n",
      "   0.    0.83  0.68 61.7   1.    4.74  0.    0.4 ]]\n",
      "\n",
      "Normalized: [[-0.51 -0.53 -0.47 -0.42 -0.4  -0.43 -0.42 -0.41 -0.37 -0.39  0.99  1.\n",
      "  -0.86 -0.32  1.44  0.24  0.09 -0.66 -0.57  0.02]]\n"
     ]
    }
   ],
   "source": [
    "first = np.array(train_features[:1])\n",
    "\n",
    "with np.printoptions(precision=2, suppress=True):\n",
    "    print('First example:', first)\n",
    "    print()\n",
    "    print('Normalized:', normalizer(first).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    normalizer,\n",
    "    layers.Dense(units=1, activation=tf.nn.sigmoid)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4446841 ],\n",
       "       [0.6397044 ],\n",
       "       [0.92892766],\n",
       "       [0.4084771 ],\n",
       "       [0.5577599 ],\n",
       "       [0.45085368],\n",
       "       [0.32913262],\n",
       "       [0.22315921],\n",
       "       [0.30762565],\n",
       "       [0.43017557]], dtype=float32)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(train_features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'dense_13/kernel:0' shape=(20, 1) dtype=float32, numpy=\n",
       "array([[ 0.41795838],\n",
       "       [ 0.1542632 ],\n",
       "       [ 0.12030333],\n",
       "       [ 0.3172319 ],\n",
       "       [ 0.3853922 ],\n",
       "       [ 0.26185203],\n",
       "       [ 0.08020937],\n",
       "       [ 0.09313154],\n",
       "       [-0.26183814],\n",
       "       [ 0.03714484],\n",
       "       [ 0.5172735 ],\n",
       "       [-0.28582034],\n",
       "       [-0.40068835],\n",
       "       [-0.40090394],\n",
       "       [-0.3877204 ],\n",
       "       [ 0.3977028 ],\n",
       "       [-0.2073951 ],\n",
       "       [-0.30394065],\n",
       "       [-0.18491915],\n",
       "       [-0.11327487]], dtype=float32)>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1047/1047 [==============================] - 4s 3ms/step - loss: 0.5264 - accuracy: 0.7288 - val_loss: 0.5100 - val_accuracy: 0.7372\n",
      "Epoch 2/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4903 - accuracy: 0.7526 - val_loss: 0.5001 - val_accuracy: 0.7449\n",
      "Epoch 3/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4819 - accuracy: 0.7574 - val_loss: 0.4952 - val_accuracy: 0.7468\n",
      "Epoch 4/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4774 - accuracy: 0.7598 - val_loss: 0.4925 - val_accuracy: 0.7490\n",
      "Epoch 5/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4744 - accuracy: 0.7616 - val_loss: 0.4905 - val_accuracy: 0.7498\n",
      "Epoch 6/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4722 - accuracy: 0.7624 - val_loss: 0.4890 - val_accuracy: 0.7497\n",
      "Epoch 7/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4703 - accuracy: 0.7636 - val_loss: 0.4873 - val_accuracy: 0.7533\n",
      "Epoch 8/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4689 - accuracy: 0.7645 - val_loss: 0.4860 - val_accuracy: 0.7520\n",
      "Epoch 9/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4677 - accuracy: 0.7653 - val_loss: 0.4852 - val_accuracy: 0.7533\n",
      "Epoch 10/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4666 - accuracy: 0.7659 - val_loss: 0.4841 - val_accuracy: 0.7545\n",
      "Epoch 11/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4655 - accuracy: 0.7665 - val_loss: 0.4837 - val_accuracy: 0.7528\n",
      "Epoch 12/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4646 - accuracy: 0.7665 - val_loss: 0.4831 - val_accuracy: 0.7554\n",
      "Epoch 13/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4639 - accuracy: 0.7673 - val_loss: 0.4820 - val_accuracy: 0.7523\n",
      "Epoch 14/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4632 - accuracy: 0.7682 - val_loss: 0.4819 - val_accuracy: 0.7556\n",
      "Epoch 15/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4626 - accuracy: 0.7687 - val_loss: 0.4806 - val_accuracy: 0.7552\n",
      "Epoch 16/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4620 - accuracy: 0.7684 - val_loss: 0.4805 - val_accuracy: 0.7564\n",
      "Epoch 17/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4615 - accuracy: 0.7690 - val_loss: 0.4796 - val_accuracy: 0.7559\n",
      "Epoch 18/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4610 - accuracy: 0.7691 - val_loss: 0.4793 - val_accuracy: 0.7569\n",
      "Epoch 19/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4605 - accuracy: 0.7698 - val_loss: 0.4789 - val_accuracy: 0.7564\n",
      "Epoch 20/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4601 - accuracy: 0.7707 - val_loss: 0.4787 - val_accuracy: 0.7575\n",
      "Epoch 21/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4597 - accuracy: 0.7704 - val_loss: 0.4780 - val_accuracy: 0.7576\n",
      "Epoch 22/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4593 - accuracy: 0.7703 - val_loss: 0.4779 - val_accuracy: 0.7579\n",
      "Epoch 23/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4590 - accuracy: 0.7707 - val_loss: 0.4775 - val_accuracy: 0.7582\n",
      "Epoch 24/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4587 - accuracy: 0.7710 - val_loss: 0.4770 - val_accuracy: 0.7577\n",
      "Epoch 25/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4583 - accuracy: 0.7718 - val_loss: 0.4771 - val_accuracy: 0.7585\n",
      "Epoch 26/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4581 - accuracy: 0.7716 - val_loss: 0.4765 - val_accuracy: 0.7584\n",
      "Epoch 27/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4578 - accuracy: 0.7711 - val_loss: 0.4761 - val_accuracy: 0.7589\n",
      "Epoch 28/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4576 - accuracy: 0.7721 - val_loss: 0.4761 - val_accuracy: 0.7584\n",
      "Epoch 29/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4573 - accuracy: 0.7724 - val_loss: 0.4759 - val_accuracy: 0.7589\n",
      "Epoch 30/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4571 - accuracy: 0.7718 - val_loss: 0.4756 - val_accuracy: 0.7583\n",
      "Epoch 31/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4568 - accuracy: 0.7721 - val_loss: 0.4755 - val_accuracy: 0.7594\n",
      "Epoch 32/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4566 - accuracy: 0.7724 - val_loss: 0.4752 - val_accuracy: 0.7591\n",
      "Epoch 33/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4565 - accuracy: 0.7724 - val_loss: 0.4750 - val_accuracy: 0.7590\n",
      "Epoch 34/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4562 - accuracy: 0.7731 - val_loss: 0.4750 - val_accuracy: 0.7591\n",
      "Epoch 35/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4560 - accuracy: 0.7724 - val_loss: 0.4752 - val_accuracy: 0.7605\n",
      "Epoch 36/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4559 - accuracy: 0.7728 - val_loss: 0.4748 - val_accuracy: 0.7597\n",
      "Epoch 37/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4558 - accuracy: 0.7734 - val_loss: 0.4743 - val_accuracy: 0.7609\n",
      "Epoch 38/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4555 - accuracy: 0.7733 - val_loss: 0.4742 - val_accuracy: 0.7602\n",
      "Epoch 39/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4554 - accuracy: 0.7736 - val_loss: 0.4742 - val_accuracy: 0.7603\n",
      "Epoch 40/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4552 - accuracy: 0.7742 - val_loss: 0.4739 - val_accuracy: 0.7607\n",
      "Epoch 41/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4551 - accuracy: 0.7740 - val_loss: 0.4737 - val_accuracy: 0.7606\n",
      "Epoch 42/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4549 - accuracy: 0.7740 - val_loss: 0.4739 - val_accuracy: 0.7611\n",
      "Epoch 43/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4548 - accuracy: 0.7741 - val_loss: 0.4735 - val_accuracy: 0.7611\n",
      "Epoch 44/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4547 - accuracy: 0.7745 - val_loss: 0.4733 - val_accuracy: 0.7621\n",
      "Epoch 45/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4546 - accuracy: 0.7742 - val_loss: 0.4733 - val_accuracy: 0.7626\n",
      "Epoch 46/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4544 - accuracy: 0.7749 - val_loss: 0.4730 - val_accuracy: 0.7618\n",
      "Epoch 47/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4543 - accuracy: 0.7747 - val_loss: 0.4729 - val_accuracy: 0.7612\n",
      "Epoch 48/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4542 - accuracy: 0.7751 - val_loss: 0.4729 - val_accuracy: 0.7622\n",
      "Epoch 49/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4541 - accuracy: 0.7747 - val_loss: 0.4726 - val_accuracy: 0.7619\n",
      "Epoch 50/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4540 - accuracy: 0.7753 - val_loss: 0.4727 - val_accuracy: 0.7622\n",
      "Epoch 51/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4539 - accuracy: 0.7752 - val_loss: 0.4725 - val_accuracy: 0.7614\n",
      "Epoch 52/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4538 - accuracy: 0.7750 - val_loss: 0.4724 - val_accuracy: 0.7627\n",
      "Epoch 53/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4537 - accuracy: 0.7751 - val_loss: 0.4722 - val_accuracy: 0.7625\n",
      "Epoch 54/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4536 - accuracy: 0.7750 - val_loss: 0.4722 - val_accuracy: 0.7621\n",
      "Epoch 55/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4535 - accuracy: 0.7756 - val_loss: 0.4721 - val_accuracy: 0.7626\n",
      "Epoch 56/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4534 - accuracy: 0.7753 - val_loss: 0.4721 - val_accuracy: 0.7620\n",
      "Epoch 57/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4533 - accuracy: 0.7756 - val_loss: 0.4720 - val_accuracy: 0.7631\n",
      "Epoch 58/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4532 - accuracy: 0.7756 - val_loss: 0.4718 - val_accuracy: 0.7627\n",
      "Epoch 59/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4532 - accuracy: 0.7753 - val_loss: 0.4720 - val_accuracy: 0.7637\n",
      "Epoch 60/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4531 - accuracy: 0.7754 - val_loss: 0.4716 - val_accuracy: 0.7631\n",
      "Epoch 61/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4529 - accuracy: 0.7761 - val_loss: 0.4721 - val_accuracy: 0.7630\n",
      "Epoch 62/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4529 - accuracy: 0.7755 - val_loss: 0.4715 - val_accuracy: 0.7643\n",
      "Epoch 63/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4528 - accuracy: 0.7756 - val_loss: 0.4715 - val_accuracy: 0.7632\n",
      "Epoch 64/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4527 - accuracy: 0.7766 - val_loss: 0.4714 - val_accuracy: 0.7643\n",
      "Epoch 65/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4527 - accuracy: 0.7768 - val_loss: 0.4713 - val_accuracy: 0.7631\n",
      "Epoch 66/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4527 - accuracy: 0.7762 - val_loss: 0.4713 - val_accuracy: 0.7650\n",
      "Epoch 67/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4526 - accuracy: 0.7759 - val_loss: 0.4711 - val_accuracy: 0.7645\n",
      "Epoch 68/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4525 - accuracy: 0.7764 - val_loss: 0.4712 - val_accuracy: 0.7631\n",
      "Epoch 69/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4525 - accuracy: 0.7760 - val_loss: 0.4709 - val_accuracy: 0.7651\n",
      "Epoch 70/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4524 - accuracy: 0.7768 - val_loss: 0.4712 - val_accuracy: 0.7649\n",
      "Epoch 71/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4523 - accuracy: 0.7763 - val_loss: 0.4711 - val_accuracy: 0.7651\n",
      "Epoch 72/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4523 - accuracy: 0.7767 - val_loss: 0.4710 - val_accuracy: 0.7632\n",
      "Epoch 73/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4522 - accuracy: 0.7765 - val_loss: 0.4710 - val_accuracy: 0.7650\n",
      "Epoch 74/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4521 - accuracy: 0.7764 - val_loss: 0.4707 - val_accuracy: 0.7637\n",
      "Epoch 75/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4521 - accuracy: 0.7768 - val_loss: 0.4706 - val_accuracy: 0.7650\n",
      "Epoch 76/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4520 - accuracy: 0.7768 - val_loss: 0.4705 - val_accuracy: 0.7650\n",
      "Epoch 77/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4520 - accuracy: 0.7773 - val_loss: 0.4706 - val_accuracy: 0.7651\n",
      "Epoch 78/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4519 - accuracy: 0.7768 - val_loss: 0.4706 - val_accuracy: 0.7642\n",
      "Epoch 79/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4518 - accuracy: 0.7771 - val_loss: 0.4706 - val_accuracy: 0.7663\n",
      "Epoch 80/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4519 - accuracy: 0.7775 - val_loss: 0.4704 - val_accuracy: 0.7650\n",
      "Epoch 81/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4518 - accuracy: 0.7775 - val_loss: 0.4704 - val_accuracy: 0.7634\n",
      "Epoch 82/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4516 - accuracy: 0.7776 - val_loss: 0.4704 - val_accuracy: 0.7659\n",
      "Epoch 83/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4517 - accuracy: 0.7774 - val_loss: 0.4703 - val_accuracy: 0.7657\n",
      "Epoch 84/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4516 - accuracy: 0.7775 - val_loss: 0.4702 - val_accuracy: 0.7648\n",
      "Epoch 85/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4516 - accuracy: 0.7774 - val_loss: 0.4702 - val_accuracy: 0.7634\n",
      "Epoch 86/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4516 - accuracy: 0.7770 - val_loss: 0.4703 - val_accuracy: 0.7642\n",
      "Epoch 87/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4515 - accuracy: 0.7779 - val_loss: 0.4701 - val_accuracy: 0.7658\n",
      "Epoch 88/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4514 - accuracy: 0.7777 - val_loss: 0.4703 - val_accuracy: 0.7654\n",
      "Epoch 89/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4514 - accuracy: 0.7776 - val_loss: 0.4701 - val_accuracy: 0.7658\n",
      "Epoch 90/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4514 - accuracy: 0.7781 - val_loss: 0.4700 - val_accuracy: 0.7655\n",
      "Epoch 91/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4514 - accuracy: 0.7778 - val_loss: 0.4700 - val_accuracy: 0.7664\n",
      "Epoch 92/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4513 - accuracy: 0.7782 - val_loss: 0.4699 - val_accuracy: 0.7652\n",
      "Epoch 93/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4513 - accuracy: 0.7780 - val_loss: 0.4701 - val_accuracy: 0.7661\n",
      "Epoch 94/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4513 - accuracy: 0.7777 - val_loss: 0.4698 - val_accuracy: 0.7657\n",
      "Epoch 95/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4512 - accuracy: 0.7782 - val_loss: 0.4698 - val_accuracy: 0.7643\n",
      "Epoch 96/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4512 - accuracy: 0.7785 - val_loss: 0.4698 - val_accuracy: 0.7644\n",
      "Epoch 97/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4511 - accuracy: 0.7784 - val_loss: 0.4701 - val_accuracy: 0.7657\n",
      "Epoch 98/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4511 - accuracy: 0.7779 - val_loss: 0.4698 - val_accuracy: 0.7652\n",
      "Epoch 99/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4510 - accuracy: 0.7780 - val_loss: 0.4697 - val_accuracy: 0.7649\n",
      "Epoch 100/100\n",
      "1047/1047 [==============================] - 3s 3ms/step - loss: 0.4510 - accuracy: 0.7776 - val_loss: 0.4700 - val_accuracy: 0.7663\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    epochs=100,\n",
    "    # Suppress logging.\n",
    "    verbose=1,\n",
    "    # Calculate validation results on 20% of the training data.\n",
    "    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(np.array(model.layers[1].kernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['index'] = [i for i in range(1, 21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.980254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.642318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.733566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.775070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.279209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.714435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.381890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.149938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.131994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.042560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.624301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.458659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.081451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.176268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.199435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.955811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.118637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.570076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.020385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.407297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "index          \n",
       "1     -1.980254\n",
       "2     -0.642318\n",
       "3     -0.733566\n",
       "4      0.775070\n",
       "5      2.279209\n",
       "6      0.714435\n",
       "7      0.381890\n",
       "8     -0.149938\n",
       "9     -0.131994\n",
       "10    -1.042560\n",
       "11    -0.624301\n",
       "12     1.458659\n",
       "13    -0.081451\n",
       "14    -0.176268\n",
       "15    -0.199435\n",
       "16    -0.955811\n",
       "17     0.118637\n",
       "18    -0.570076\n",
       "19     1.020385\n",
       "20    -1.407297"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B01 Coastal aerosol - 1.72,\n",
    "B04 Red - 1.494937,\n",
    "B05 Vegetation red edge - 2.550103,\n",
    "B08 NIR - -1.136251\n",
    "B09 Water vapour - -1.161327\n",
    "B10 SWIR Cirrus - -1.052148\n",
    "B11 SWIR - 2.098709\n",
    "CLP - -1.277699"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [ACC]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model(norm):\n",
    "    model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='sgd',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model = build_and_compile_model(normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4507 - accuracy: 0.7719 - val_loss: 0.4451 - val_accuracy: 0.7788\n",
      "Epoch 2/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4430 - accuracy: 0.7789 - val_loss: 0.4373 - val_accuracy: 0.7857\n",
      "Epoch 3/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4358 - accuracy: 0.7867 - val_loss: 0.4312 - val_accuracy: 0.7919\n",
      "Epoch 4/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4293 - accuracy: 0.7926 - val_loss: 0.4258 - val_accuracy: 0.8010\n",
      "Epoch 5/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4223 - accuracy: 0.8001 - val_loss: 0.4187 - val_accuracy: 0.8036\n",
      "Epoch 6/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4154 - accuracy: 0.8067 - val_loss: 0.4108 - val_accuracy: 0.8106\n",
      "Epoch 7/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4081 - accuracy: 0.8151 - val_loss: 0.4052 - val_accuracy: 0.8171\n",
      "Epoch 8/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.4013 - accuracy: 0.8222 - val_loss: 0.3990 - val_accuracy: 0.8254\n",
      "Epoch 9/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3952 - accuracy: 0.8256 - val_loss: 0.3996 - val_accuracy: 0.8232\n",
      "Epoch 10/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3895 - accuracy: 0.8286 - val_loss: 0.3881 - val_accuracy: 0.8340\n",
      "Epoch 11/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3838 - accuracy: 0.8324 - val_loss: 0.3840 - val_accuracy: 0.8323\n",
      "Epoch 12/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3785 - accuracy: 0.8349 - val_loss: 0.3854 - val_accuracy: 0.8268\n",
      "Epoch 13/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3753 - accuracy: 0.8365 - val_loss: 0.3783 - val_accuracy: 0.8352\n",
      "Epoch 14/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3718 - accuracy: 0.8379 - val_loss: 0.3774 - val_accuracy: 0.8290\n",
      "Epoch 15/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3690 - accuracy: 0.8380 - val_loss: 0.3734 - val_accuracy: 0.8362\n",
      "Epoch 16/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3656 - accuracy: 0.8401 - val_loss: 0.3761 - val_accuracy: 0.8333\n",
      "Epoch 17/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3644 - accuracy: 0.8388 - val_loss: 0.3753 - val_accuracy: 0.8338\n",
      "Epoch 18/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3618 - accuracy: 0.8427 - val_loss: 0.3969 - val_accuracy: 0.8117\n",
      "Epoch 19/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3596 - accuracy: 0.8420 - val_loss: 0.3650 - val_accuracy: 0.8398\n",
      "Epoch 20/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3582 - accuracy: 0.8429 - val_loss: 0.3623 - val_accuracy: 0.8411\n",
      "Epoch 21/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3564 - accuracy: 0.8425 - val_loss: 0.3625 - val_accuracy: 0.8393\n",
      "Epoch 22/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3546 - accuracy: 0.8435 - val_loss: 0.3600 - val_accuracy: 0.8403\n",
      "Epoch 23/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3534 - accuracy: 0.8441 - val_loss: 0.3773 - val_accuracy: 0.8329\n",
      "Epoch 24/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3519 - accuracy: 0.8438 - val_loss: 0.3584 - val_accuracy: 0.8444\n",
      "Epoch 25/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3507 - accuracy: 0.8451 - val_loss: 0.3813 - val_accuracy: 0.8293\n",
      "Epoch 26/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3494 - accuracy: 0.8459 - val_loss: 0.3550 - val_accuracy: 0.8453\n",
      "Epoch 27/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3478 - accuracy: 0.8470 - val_loss: 0.3629 - val_accuracy: 0.8429\n",
      "Epoch 28/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3464 - accuracy: 0.8479 - val_loss: 0.3514 - val_accuracy: 0.8462\n",
      "Epoch 29/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3460 - accuracy: 0.8470 - val_loss: 0.3582 - val_accuracy: 0.8427\n",
      "Epoch 30/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3439 - accuracy: 0.8482 - val_loss: 0.3559 - val_accuracy: 0.8430\n",
      "Epoch 31/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3421 - accuracy: 0.8484 - val_loss: 0.3600 - val_accuracy: 0.8391\n",
      "Epoch 32/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3415 - accuracy: 0.8496 - val_loss: 0.3538 - val_accuracy: 0.8456\n",
      "Epoch 33/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3402 - accuracy: 0.8508 - val_loss: 0.3873 - val_accuracy: 0.8278\n",
      "Epoch 34/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3393 - accuracy: 0.8504 - val_loss: 0.3670 - val_accuracy: 0.8417\n",
      "Epoch 35/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3376 - accuracy: 0.8520 - val_loss: 0.3455 - val_accuracy: 0.8470\n",
      "Epoch 36/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3370 - accuracy: 0.8507 - val_loss: 0.3430 - val_accuracy: 0.8470\n",
      "Epoch 37/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3353 - accuracy: 0.8514 - val_loss: 0.3415 - val_accuracy: 0.8531\n",
      "Epoch 38/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3344 - accuracy: 0.8536 - val_loss: 0.3382 - val_accuracy: 0.8545\n",
      "Epoch 39/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3329 - accuracy: 0.8549 - val_loss: 0.3731 - val_accuracy: 0.8354\n",
      "Epoch 40/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3326 - accuracy: 0.8532 - val_loss: 0.3785 - val_accuracy: 0.8315\n",
      "Epoch 41/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3322 - accuracy: 0.8537 - val_loss: 0.3505 - val_accuracy: 0.8465\n",
      "Epoch 42/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3303 - accuracy: 0.8539 - val_loss: 0.3439 - val_accuracy: 0.8483\n",
      "Epoch 43/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3280 - accuracy: 0.8547 - val_loss: 0.3318 - val_accuracy: 0.8522\n",
      "Epoch 44/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3279 - accuracy: 0.8557 - val_loss: 0.3525 - val_accuracy: 0.8440\n",
      "Epoch 45/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3268 - accuracy: 0.8566 - val_loss: 0.3309 - val_accuracy: 0.8560\n",
      "Epoch 46/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3266 - accuracy: 0.8569 - val_loss: 0.3454 - val_accuracy: 0.8466\n",
      "Epoch 47/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3252 - accuracy: 0.8571 - val_loss: 0.3543 - val_accuracy: 0.8409\n",
      "Epoch 48/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3243 - accuracy: 0.8565 - val_loss: 0.3426 - val_accuracy: 0.8462\n",
      "Epoch 49/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3238 - accuracy: 0.8572 - val_loss: 0.3503 - val_accuracy: 0.8515\n",
      "Epoch 50/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3232 - accuracy: 0.8587 - val_loss: 0.3387 - val_accuracy: 0.8521\n",
      "Epoch 51/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3219 - accuracy: 0.8591 - val_loss: 0.3238 - val_accuracy: 0.8577\n",
      "Epoch 52/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3216 - accuracy: 0.8600 - val_loss: 0.3240 - val_accuracy: 0.8568\n",
      "Epoch 53/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3204 - accuracy: 0.8596 - val_loss: 0.3641 - val_accuracy: 0.8418\n",
      "Epoch 54/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3195 - accuracy: 0.8602 - val_loss: 0.3245 - val_accuracy: 0.8577\n",
      "Epoch 55/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3200 - accuracy: 0.8594 - val_loss: 0.3484 - val_accuracy: 0.8506\n",
      "Epoch 56/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3194 - accuracy: 0.8594 - val_loss: 0.3247 - val_accuracy: 0.8558\n",
      "Epoch 57/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3182 - accuracy: 0.8605 - val_loss: 0.3263 - val_accuracy: 0.8559\n",
      "Epoch 58/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3169 - accuracy: 0.8608 - val_loss: 0.3344 - val_accuracy: 0.8515\n",
      "Epoch 59/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3167 - accuracy: 0.8615 - val_loss: 0.3348 - val_accuracy: 0.8533\n",
      "Epoch 60/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3164 - accuracy: 0.8617 - val_loss: 0.3580 - val_accuracy: 0.8387\n",
      "Epoch 61/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3156 - accuracy: 0.8631 - val_loss: 0.3363 - val_accuracy: 0.8543\n",
      "Epoch 62/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3152 - accuracy: 0.8624 - val_loss: 0.3200 - val_accuracy: 0.8599\n",
      "Epoch 63/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3145 - accuracy: 0.8614 - val_loss: 0.3234 - val_accuracy: 0.8567\n",
      "Epoch 64/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3135 - accuracy: 0.8646 - val_loss: 0.3221 - val_accuracy: 0.8579\n",
      "Epoch 65/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3136 - accuracy: 0.8637 - val_loss: 0.3280 - val_accuracy: 0.8561\n",
      "Epoch 66/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3123 - accuracy: 0.8654 - val_loss: 0.3236 - val_accuracy: 0.8572\n",
      "Epoch 67/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3120 - accuracy: 0.8639 - val_loss: 0.3171 - val_accuracy: 0.8623\n",
      "Epoch 68/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3120 - accuracy: 0.8647 - val_loss: 0.3241 - val_accuracy: 0.8573\n",
      "Epoch 69/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3117 - accuracy: 0.8637 - val_loss: 0.3177 - val_accuracy: 0.8601\n",
      "Epoch 70/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3103 - accuracy: 0.8657 - val_loss: 0.3225 - val_accuracy: 0.8593\n",
      "Epoch 71/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3100 - accuracy: 0.8664 - val_loss: 0.3344 - val_accuracy: 0.8531\n",
      "Epoch 72/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3097 - accuracy: 0.8643 - val_loss: 0.3361 - val_accuracy: 0.8504\n",
      "Epoch 73/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3085 - accuracy: 0.8663 - val_loss: 0.3186 - val_accuracy: 0.8615\n",
      "Epoch 74/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3091 - accuracy: 0.8655 - val_loss: 0.3198 - val_accuracy: 0.8620\n",
      "Epoch 75/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3087 - accuracy: 0.8652 - val_loss: 0.3140 - val_accuracy: 0.8616\n",
      "Epoch 76/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3071 - accuracy: 0.8664 - val_loss: 0.3123 - val_accuracy: 0.8642\n",
      "Epoch 77/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3073 - accuracy: 0.8681 - val_loss: 0.3201 - val_accuracy: 0.8540\n",
      "Epoch 78/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3065 - accuracy: 0.8672 - val_loss: 0.3321 - val_accuracy: 0.8573\n",
      "Epoch 79/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3061 - accuracy: 0.8679 - val_loss: 0.3176 - val_accuracy: 0.8631\n",
      "Epoch 80/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3057 - accuracy: 0.8659 - val_loss: 0.3194 - val_accuracy: 0.8595\n",
      "Epoch 81/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3048 - accuracy: 0.8680 - val_loss: 0.3189 - val_accuracy: 0.8624\n",
      "Epoch 82/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3045 - accuracy: 0.8681 - val_loss: 0.3142 - val_accuracy: 0.8622\n",
      "Epoch 83/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3049 - accuracy: 0.8678 - val_loss: 0.3094 - val_accuracy: 0.8640\n",
      "Epoch 84/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3036 - accuracy: 0.8676 - val_loss: 0.3164 - val_accuracy: 0.8629\n",
      "Epoch 85/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3040 - accuracy: 0.8686 - val_loss: 0.3296 - val_accuracy: 0.8525\n",
      "Epoch 86/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3025 - accuracy: 0.8687 - val_loss: 0.3155 - val_accuracy: 0.8628\n",
      "Epoch 87/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3026 - accuracy: 0.8684 - val_loss: 0.3254 - val_accuracy: 0.8560\n",
      "Epoch 88/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3019 - accuracy: 0.8686 - val_loss: 0.3125 - val_accuracy: 0.8654\n",
      "Epoch 89/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3025 - accuracy: 0.8683 - val_loss: 0.3077 - val_accuracy: 0.8651\n",
      "Epoch 90/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3007 - accuracy: 0.8707 - val_loss: 0.3119 - val_accuracy: 0.8628\n",
      "Epoch 91/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3004 - accuracy: 0.8699 - val_loss: 0.3408 - val_accuracy: 0.8479\n",
      "Epoch 92/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3004 - accuracy: 0.8691 - val_loss: 0.3868 - val_accuracy: 0.8354\n",
      "Epoch 93/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.3008 - accuracy: 0.8693 - val_loss: 0.3061 - val_accuracy: 0.8673\n",
      "Epoch 94/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.2991 - accuracy: 0.8708 - val_loss: 0.3091 - val_accuracy: 0.8642\n",
      "Epoch 95/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.2994 - accuracy: 0.8709 - val_loss: 0.3053 - val_accuracy: 0.8657\n",
      "Epoch 96/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.2987 - accuracy: 0.8713 - val_loss: 0.3146 - val_accuracy: 0.8608\n",
      "Epoch 97/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.2983 - accuracy: 0.8716 - val_loss: 0.3057 - val_accuracy: 0.8657\n",
      "Epoch 98/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.2988 - accuracy: 0.8712 - val_loss: 0.3078 - val_accuracy: 0.8642\n",
      "Epoch 99/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.2973 - accuracy: 0.8721 - val_loss: 0.3290 - val_accuracy: 0.8559\n",
      "Epoch 100/100\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.2970 - accuracy: 0.8717 - val_loss: 0.3457 - val_accuracy: 0.8492\n"
     ]
    }
   ],
   "source": [
    "history = dnn_model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    validation_split=0.2,\n",
    "    verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
